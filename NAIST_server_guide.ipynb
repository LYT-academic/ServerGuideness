{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYFTbu4wOODP"
      },
      "source": [
        "# NAIST (Nara institute of science and technology) High Performance Computational Server Guide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzDG_fd1bZ7R"
      },
      "source": [
        "This is a note recording hands-on process as a supplement to the guideness provided by ITC center as following:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ9Lu2xA2vYw"
      },
      "source": [
        "NAIST Server Guidebook:  \n",
        "https://itcw3.naist.jp/ITC-local/manual/cc21/index.html\n",
        "\n",
        "NAIST GPU Guidebook:  \n",
        "https://itcw3.naist.jp/ITC-local/manual/cc21/Microsoft_Azure_CloudGPU_20230802.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyurQUVxa70S"
      },
      "source": [
        "## SSH log in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2MyKCPSOZ_z"
      },
      "source": [
        "**1.Normal login from your PC to server**\n",
        "\n",
        "```bash\n",
        "# Private PC terminal\n",
        "\n",
        "# method 1\n",
        "ssh [mandara account]@[server_node].naist.jp\n",
        "# method 2\n",
        "ssh -l [mandara_account] [server_node]\n",
        "\n",
        "```\n",
        "For instance, mandara_account is 'lyt', accessing dev node 'cc21dev0' or 'cc21dev1' are as following:\n",
        "```bash\n",
        "# Private PC terminal\n",
        "\n",
        "# method 1\n",
        "ssh lyt@cc21dev0.naist.jp\n",
        "# method 2\n",
        "ssh -l lyt cc21dev0\n",
        "\n",
        "```\n",
        "\n",
        "And then enter your mandara password."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV-hrqKvayvC"
      },
      "source": [
        "### 2.ssh login without password\n",
        "(1). create ssh key pairs in your private PC.\n",
        "```bash\n",
        "# Private PC terminal\n",
        "ssh-keygen -t rsa -b 4096 -C \"[your email]\" -f ~/.ssh/[name]\n",
        "# For instance\n",
        "# ssh-keygen -t rsa -b 4096 -C \"lyt@gmail.com\" -f ~/.ssh/rsa-server\n",
        "```\n",
        "**Notice:**   \n",
        "In '~/.ssh/' folder, 'rsa-server' file is your private key, keep it safe and don't copy to anybody or copy to internet. 'rsa-server.pub' file is your public key, you can copy it to server you want to login.\n",
        "\n",
        "(2). check 'authorized_keys' file in server.   \n",
        "```bash\n",
        "# Remote server terminal\n",
        "ls ~/.ssh/\n",
        "```\n",
        "If no 'authorized_keys' file there, create one.\n",
        "```bash\n",
        "# Remote server terminal\n",
        "touch ~/.ssh/authorized_keys\n",
        "```\n",
        "(3) copy your public key to remote server '~/.ssh/authorized_keys'\n",
        "\n",
        "```bash\n",
        "# Private PC terminal\n",
        "ssh-copy-id -i ~/.ssh/rsa-server.pub lyt@cc21dev0\n",
        "```\n",
        "(4) login by indicating identified file\n",
        "``` bash\n",
        "# Private PC terminal\n",
        "ssh -l lyt cc21dev0 -i ~/.ssh/rsa-server\n",
        "# or\n",
        "ssh lyt@cc21dev0 -i ~/.ssh/rsa-server\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJswZ64u22I_"
      },
      "source": [
        "Azure HPC: NVIDIA A100, 24 core, 80GB GPU memory, 220 GB memory,880GB local storage.\n",
        "\n",
        "MAC Studio M4 Max: 16 core CPU, 40 core GPU, 128 GB unit memory, 1TB storage -> 528300 yen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY8SmVakiLIQ"
      },
      "source": [
        "## change default shell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSBHIO7HiOn7"
      },
      "source": [
        "### 1. check your default shell  \n",
        "Ref: https://unix.stackexchange.com/questions/136423/making-zsh-default-shell-without-root-access\n",
        "\n",
        "```bash\n",
        "echo $SHELL\n",
        ">>>/bin/csh  # C Shell, an old Unix shell. I want to change to zsh or bash shell.\n",
        "\n",
        "# Change to zsh shell.\n",
        "## check zsh existance\n",
        "which zsh\n",
        ">>> /usr/bin/zsh. # nice, have zsh\n",
        "\n",
        "chsh -s /usr/bin/zsh\n",
        ">>>chsh: user 'lyt' does not exist in /etc/passwd\n",
        "# ok, failed because lacking admin privileges.\n",
        "\n",
        "getent passwd $(whoami)  # check if account is managed by Centralized identity services\n",
        ">>> XXX:/work/lyt:/bin/csh\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emeM96R8Sp5z"
      },
      "source": [
        "### 2. Change to zsh shell\n",
        "\n",
        "\n",
        "```bash\n",
        "# in server terminal\n",
        "vim .login # for csh shell, it will init by .login file under home directory\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "```bash\n",
        "# add following content into .login file\n",
        "if ( $?ZSH_VERSION == 0 ) then\n",
        "    # echo \"testpoint1:.login\"\n",
        "    if ( -x /usr/bin/zsh ) then\n",
        "        # echo \"testpoint2:.login\"\n",
        "        exec /usr/bin/zsh\n",
        "    else if ( -x /bin/zsh ) then\n",
        "        # echo \"testpoint3:.login\"\n",
        "        exec /bin/zsh\n",
        "    endif\n",
        "endif\n",
        "\n",
        "# enter `:`\n",
        "# enter `wq` for saving and close file\n",
        "```\n",
        "\n",
        "Now re-login through ssh, zsh shell will be processed. If you want to change zsh theme by oh-my-zsh, change it in .zshrc file.\n",
        "\n",
        "\n",
        "```bash\n",
        "# in .zshrc file\n",
        "ZSH_THEME=\"agnoster\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaeCTstvVJPA"
      },
      "source": [
        "Summary:  \n",
        "\n",
        "| File      | load condition | object |\n",
        "| ----------- | ----------- |-----|\n",
        "| .bash_profile | Bash first choice for login config | Bash|\n",
        "| .profile | Universal choice for login config       | sh, dash, ksh, zsh(partial).bash_profile(if no .bash_profile)|\n",
        "|.cshrc | every time shell was exec, like .bshrc for csh | csh, tcsh |\n",
        "|.login | login, similar to .bash_profile | csh, tcsh |\n",
        "|.logout| logout | csh, tcsh |\n",
        "|.bash_logout | bash logout read | bash |\n",
        "|.zlogout| zsh logout read | zsh |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAfe9BSeaVym"
      },
      "source": [
        "## Assign job through slurm\n",
        "srun for interactive job, and sbatch for batch job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9k0jVn2abOK"
      },
      "source": [
        "### 1. Check partition, node list and its state\n",
        "\n",
        "(1) `sinfo`: list all node, partition and its state.\n",
        "\n",
        "| abbreviate | state      | meaning                               |\n",
        "| :--------- | :--------- | ------------------------------------- |\n",
        "| alloc      | allocated  | running task                          |\n",
        "| block      | blocked    |                                       |\n",
        "| comp       | completing |                                       |\n",
        "| down       | down       | node can not be used                  |\n",
        "| drain      | drained    |                                       |\n",
        "| drng       | draining   |                                       |\n",
        "| fail       | fail       |                                       |\n",
        "| failg      | failing    |                                       |\n",
        "| futr       | future     |                                       |\n",
        "| idle       | idle       | node is free and can be used          |\n",
        "| maint      | maint      |                                       |\n",
        "| mix        | mixed      | partial node is free, partial is busy |\n",
        "| npc        | perfctrs   |                                       |\n",
        "| plnd       | planned    |                                       |\n",
        "| pow_dn     | power_down |                                       |\n",
        "| pow_up     | power_up   |                                       |\n",
        "| resv       | reserved   |                                       |\n",
        "| unk        | unknown    |                                       |\n",
        "\n",
        "\n",
        "\n",
        "```bash\n",
        "lyt@cc21dev0  ~  sinfo\n",
        "PARTITION        AVAIL  TIMELIMIT  NODES  STATE NODELIST\n",
        "cluster_short*      up    4:00:00      2   comp cc21cluster[00,13]\n",
        "cluster_short*      up    4:00:00      1    mix cc21cluster05\n",
        "cluster_short*      up    4:00:00     35  alloc cc21cluster[01-04,06-12,14-37]\n",
        "cluster_long        up 4-04:00:00     18  alloc cc21cluster[20-37]\n",
        "cluster_low         up 41-16:00:0      2   comp cc21cluster[00,13]\n",
        "cluster_low         up 41-16:00:0      1    mix cc21cluster05\n",
        "cluster_low         up 41-16:00:0     17  alloc cc21cluster[01-04,06-12,14-19]\n",
        "cluster_intr        up   10:00:00      2   comp cc21cluster[00,13]\n",
        "cluster_intr        up   10:00:00      1    mix cc21cluster05\n",
        "cluster_intr        up   10:00:00     17  alloc cc21cluster[01-04,06-12,14-19]\n",
        "gpu_short           up    4:00:00      5    mix cc21gpu[01-02,04-06]\n",
        "gpu_short           up    4:00:00      1  alloc cc21gpu00\n",
        "gpu_short           up    4:00:00      2   idle cc21gpu[03,07]\n",
        "gpu_long            up 4-04:00:00      3    mix cc21gpu[04-06]\n",
        "gpu_long            up 4-04:00:00      1   idle cc21gpu07\n",
        "gpu_intr            up   10:00:00      5    mix cc21gpu[01-02,04-06]\n",
        "gpu_intr            up   10:00:00      1  alloc cc21gpu00\n",
        "gpu_intr            up   10:00:00      2   idle cc21gpu[03,07]\n",
        "hmem_short          up    4:00:00      1  alloc cc21hmem00\n",
        "hmem_short          up    4:00:00      1   idle cc21hmem01\n",
        "hmem_long           up 4-04:00:00      1  alloc cc21hmem00\n",
        "hmem_long           up 4-04:00:00      1   idle cc21hmem01\n",
        "hmem_intr           up   10:00:00      1  alloc cc21hmem00\n",
        "hmem_intr           up   10:00:00      1   idle cc21hmem01\n",
        "msas_short          up    4:00:00      1    mix cc21msas\n",
        "msas_long           up 4-04:00:00      1    mix cc21msas\n",
        "msas_intr           up   10:00:00      1    mix cc21msas\n",
        "azuregpu1_long      up 4-04:00:00      5  idle~ cc19azuregpu[100-104]\n",
        "azuregpu1_intr      up   10:00:00      5  idle~ cc19azuregpu[100-104]\n",
        "ocigpu8a100_long    up 4-04:00:00      1  idle~ cc21ocigpu8a110\n",
        "ocigpu8a100_long    up 4-04:00:00      1 drain~ cc21ocigpu8a100\n",
        "ocigpu8a100_intr    up   10:00:00      1  idle~ cc21ocigpu8a110\n",
        "ocigpu8a100_intr    up   10:00:00      1 drain~ cc21ocigpu8a100\n",
        "ocigpu1a10_long     up 4-04:00:00      7  idle~ cc21ocigpu1a[001-007]\n",
        "ocigpu1a10_long     up 4-04:00:00      1    mix cc21ocigpu1a000\n",
        "ocigpu1a10_intr     up   10:00:00      7  idle~ cc21ocigpu1a[001-007]\n",
        "ocigpu1a10_intr     up   10:00:00      1    mix cc21ocigpu1a000\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Assign partition or node for your work      \n",
        "\n",
        "(1). Assign partition or node in command line\n",
        "\n",
        "- `srun` case\n",
        "  \n",
        "```bash\n",
        "# interactive pattern: srun -p cluster_intr --pty bash -l\n",
        "# -p -> partition \n",
        "lyt@cc21dev0 ~ srun -p cluster_intr --pty bash -l\n",
        "\n",
        "srun: job 3468405 queued and waiting for resources\n",
        "srun: job 3468405 has been allocated resources\n",
        "testpoin1: .profile  # This line comes because I add a testpoint in .profile file, it is clear that srun read '.profile' config file.\n",
        "lyt@cc21cluster05:~$  # in this case, cc21cluster05 node was allocated to me, the following command will be excuted in this node.\n",
        "```\n",
        "\n",
        "Let's run test.sh file for testing, the file content as following:\n",
        "```\n",
        "#!/bin/bash -l\n",
        "success test.\n",
        "```\n",
        "\n",
        "Under interactive mode, we can send command like this ðŸ‘‡\n",
        "```bash\n",
        "lyt@cc21cluster05: bash test.sh\n",
        "success test.\n",
        "\n",
        "lyt@cc21cluster05: exit  # logout node\n",
        "logout\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `sbatch` case     \n",
        "  \n",
        "you can assign batch job by `sbatch`, the parameter can be assigned in bash script file through '#SBATCH' or in command line.\n",
        "The priority: command > script, so if same parameter is provided in command, it will replace that in script.\n",
        "\n",
        "Now example, we have a file called 'test_cpu_run.sh' under 'GPU_test' folder.\n",
        "The content is like:\n",
        "```\n",
        "#!/bin/bash -l\n",
        "#SBATCH -p azuregpu1_intr  # Notice, here I assigned 'azuregpu1_intr' partition, later I will reassign in command line. \n",
        "#SBATCH --chdir=/work/lyt  # working path\n",
        "#SBATCH --job-name=test_cpu\n",
        "#SBATCH --output=test_cpu_output.txt  # output will recorded in this file and save in your work space.\n",
        "\n",
        "# Load modules if necessary, e.g., Anaconda or Python environment\n",
        "# module load anaconda\n",
        "# source activate your_env\n",
        "\n",
        "echo \"Starting CPU job...list miniconda if installed\"\n",
        "apt list --installed | grep miniconda\n",
        "echo \"Job finished.\"\n",
        "```\n",
        "\n",
        "```bash\n",
        "# batch job mode: sbatch -p cluster_intr GPU_test/test_cpu_run.sh\n",
        "lyt@cc21dev0 ~ sbatch -p cluster_low GPU_test/test_cpu_run.sh  # Notice here I covered the -p parameter in command line.\n",
        "\n",
        "Submitted batch job 3468410\n",
        "```\n",
        "\n",
        "\n",
        "Check 'work/lyt/' folder, 'test_cpu_output.txt' file was saved, output as following:\n",
        "\n",
        "```text\n",
        "testpoin1: .profile\n",
        "Starting CPU job...list miniconda if installed\n",
        "\n",
        "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
        "\n",
        "Job finished.\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GPU node - super parallel calculation nodes/ Cloud HPC Node (OCI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I only test super parallel calculation nodes(SPC), OCI is not checked yet.\n",
        "Here is the test flow for SPC nodes.\n",
        "\n",
        "(1). `sbatch`\n",
        "\n",
        "In cc21dev0 node, 'test_gpu_run.sh' and 'test_gpu.py' is under GPU_test folder. \n",
        "\n",
        "```bash\n",
        "lyt@cc21dev0  ~ sbatch -p gpu_short GPU_test/test_gpu_run.sh\n",
        "Submitted batch job 3468418\n",
        "```\n",
        "\n",
        "Output file 'test_gpu_output.txt':\n",
        "``` text\n",
        "testpoin1: .profile\n",
        "Starting GPU test job...\n",
        "Running test_gpu.py\n",
        "Traceback (most recent call last):\n",
        "  File \"/work/lyt/GPU_test/test_gpu.py\", line 2, in <module>\n",
        "    import torch\n",
        "ModuleNotFoundError: No module named 'torch'  # Not setting environment yet, so cannot run torch package.\n",
        "Job finished.\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ABFFqbBOf1a"
      },
      "source": [
        "## GPU node - Cloud HPC Node (Azure)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-_LF5X1ma0U"
      },
      "source": [
        "### 1. Copy data and script to azure specific folder\n",
        "\n",
        "Ref:\n",
        "https://itcw3.naist.jp/ITC-local/manual/cc21/Microsoft_Azure_CloudGPU_20230802.pdf\n",
        "(page 17-19)\n",
        "\n",
        "Because Azure HPC center is in American, so need to copy data and script into specific Azure folder 'azure-cc1' through `sftp` interactive command.\n",
        "Azure folder is a temperal place for your work, and has a limitation of 500GB for each user.\n",
        "\n",
        "**copy file/folder from dev node to Azure folder:**\n",
        "\n",
        "\n",
        "```bash\n",
        "# upload folder\n",
        "sftp azure-cc1 <<< 'put -r [dev_node/folder] [remote/folder]'\n",
        "# upload file\n",
        "sftp azure-cc1 <<< 'put [dev_node/file] [remote/file]'\n",
        "\n",
        "# For instance, upload test folder\n",
        "# sftp azure-cc1 <<< 'put -r test test'\n",
        "\n",
        "```\n",
        "\n",
        "**get file/folder from Azure folder to dev node:**\n",
        "```bash\n",
        "# get folder\n",
        "sftp azure-cc1 <<< 'get -r [remote/folder] [dev_node/folder]'\n",
        "# get file\n",
        "sftp azure-cc1 <<< 'put [remote/file] [dev_node/file]'\n",
        "\n",
        "# For instance, upload test folder\n",
        "# sftp azure-cc1 <<< 'get test test'\n",
        "\n",
        "```\n",
        "\n",
        "**It is also possible using interactive style:**\n",
        "```bash\n",
        "# open interactive line\n",
        "sftp azure-cc1\n",
        "\n",
        "# list file/folders\n",
        "ls\n",
        "\n",
        "# remove file/folders\n",
        "rm [file]\n",
        "rm -r [folder]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoBjCLElO4nt"
      },
      "source": [
        "### 2. Interactive command\n",
        "\n",
        "open a GPU node in interactive environment\n",
        "\n",
        "```bash\n",
        "srun â€“p azuregpu1_intr --gres=gpu:1 --chdir=/work/(account) --pty bash\n",
        "# For instance\n",
        "# srun â€“p azuregpu1_intr --gres=gpu:1 --chdir=/work/lyt --pty bash\n",
        "```\n",
        "\n",
        "\n",
        "Memo: Azure HPC has really heavy delay, maybe that's why it is idle. ðŸ¤·\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Others\n",
        "- Conda environment should install in which node?\n",
        "- what's the diffrence between `module load` and conda virtual environment\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conda environment should install in which node?\n",
        "Conda environment should install in development node cc21dev0 or cc21dev1.\n",
        "Because every calculation node could access cc21dev0 node [mandara account]/work/, however, the calculation node assigned to you is dynamic.\n",
        "So setting your virtual environment like conda under cc21dev0 node, and write following lauch command in your running bash script.\n",
        "\n",
        "```bash\n",
        "source /work/lyt/miniconda3/bin/activate\n",
        "conda activate [myenv]  # myenv is your environment name, don't need typing [].\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What's the diffrence between `module load` and conda virtual environment"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "datapreprocess",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
