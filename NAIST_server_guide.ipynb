{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYFTbu4wOODP"
      },
      "source": [
        "# NAIST (Nara institute of science and technology) High Performance Computational Server Guide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzDG_fd1bZ7R"
      },
      "source": [
        "This is a note recording hands-on process as a supplement to the guideness provided by ITC center as following:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ9Lu2xA2vYw"
      },
      "source": [
        "NAIST Server Guidebook:  \n",
        "https://itcw3.naist.jp/ITC-local/manual/cc21/index.html\n",
        "\n",
        "NAIST GPU Guidebook:  \n",
        "https://itcw3.naist.jp/ITC-local/manual/cc21/Microsoft_Azure_CloudGPU_20230802.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyurQUVxa70S"
      },
      "source": [
        "## SSH log in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2MyKCPSOZ_z"
      },
      "source": [
        "**1.Normal login from your PC to server**\n",
        "\n",
        "```bash\n",
        "# Private PC terminal\n",
        "\n",
        "# method 1\n",
        "ssh [mandara account]@[server_node].naist.jp\n",
        "# method 2\n",
        "ssh -l [mandara_account] [server_node]\n",
        "\n",
        "```\n",
        "For instance, mandara_account is 'lyt', accessing dev node 'cc21dev0' or 'cc21dev1' are as following:\n",
        "```bash\n",
        "# Private PC terminal\n",
        "\n",
        "# method 1\n",
        "ssh lyt@cc21dev0.naist.jp\n",
        "# method 2\n",
        "ssh -l lyt cc21dev0\n",
        "\n",
        "```\n",
        "\n",
        "And then enter your mandara password."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV-hrqKvayvC"
      },
      "source": [
        "### 2.ssh login through ssh-keygen\n",
        "(1). create ssh key pairs in your private PC.\n",
        "```bash\n",
        "# Private PC terminal\n",
        "ssh-keygen -t rsa -b 4096 -C \"[your email]\" -f ~/.ssh/[name]\n",
        "# For instance\n",
        "# ssh-keygen -t rsa -b 4096 -C \"lyt@gmail.com\" -f ~/.ssh/rsa-server\n",
        "```\n",
        "**Notice:**   \n",
        "In '~/.ssh/' folder, 'rsa-server' file is your private key, keep it safe and don't copy to anybody or copy to internet. 'rsa-server.pub' file is your public key, you can copy it to server you want to login.\n",
        "\n",
        "(2). check 'authorized_keys' file in server.   \n",
        "```bash\n",
        "# Remote server terminal\n",
        "ls ~/.ssh/\n",
        "```\n",
        "If no 'authorized_keys' file there, create one.\n",
        "```bash\n",
        "# Remote server terminal\n",
        "touch ~/.ssh/authorized_keys\n",
        "```\n",
        "(3) copy your public key to remote server '~/.ssh/authorized_keys'\n",
        "\n",
        "```bash\n",
        "# Private PC terminal\n",
        "ssh-copy-id -i ~/.ssh/rsa-server.pub lyt@cc21dev0\n",
        "```\n",
        "(4) login by indicating identified file\n",
        "``` bash\n",
        "# Private PC terminal\n",
        "ssh -l lyt cc21dev0 -i ~/.ssh/rsa-server\n",
        "# or\n",
        "ssh lyt@cc21dev0 -i ~/.ssh/rsa-server\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.ssh log in off-campus\n",
        "Ref:ã€€https://itcw3.naist.jp/ITC-local/remotelogin/ssh.en.html\n",
        "\n",
        "Access server from off-campus need to login sh.naist.jp first to avoid fire wall.\n",
        "So repeat section2 to for ssh-keygen login on sh.naist.jp\n",
        "\n",
        "Step1. create ssh-keygen pairs as described in section '2.ssh login through ssh-keygen-(1). create ssh key pairs in your private PC'\n",
        "\n",
        "Step2. copy public key and [submitted](https://mandara-request.naist.jp/sh.naist.jp/sh-registration.ja.cgi) to itc center, they will help to copy your public key into sh.naist.jp `~/.ssh/authorized_keys`\n",
        "\n",
        "Step3. login method\n",
        "```bash\n",
        "% slogin -l [mandara name] [server name(sh.naist.jp)]\n",
        "# For instance, mandara_name is 'lyt'\n",
        "% slogin -l lyt sh.naist.jp\n",
        "éµ '/home/itc/lyt/.ssh/id_rsa' ã®ãƒ‘ã‚¹ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJswZ64u22I_"
      },
      "source": [
        "Azure HPC: NVIDIA A100, 24 core, 80GB GPU memory, 220 GB memory,880GB local storage.\n",
        "\n",
        "MAC Studio M4 Max: 16 core CPU, 40 core GPU, 128 GB unit memory, 1TB storage -> 528300 yen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY8SmVakiLIQ"
      },
      "source": [
        "## change default shell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSBHIO7HiOn7"
      },
      "source": [
        "### 1. check your default shell  \n",
        "Ref: https://unix.stackexchange.com/questions/136423/making-zsh-default-shell-without-root-access\n",
        "\n",
        "```bash\n",
        "echo $SHELL\n",
        ">>>/bin/csh  # C Shell, an old Unix shell. I want to change to zsh or bash shell.\n",
        "\n",
        "# Change to zsh shell.\n",
        "## check zsh existance\n",
        "which zsh\n",
        ">>> /usr/bin/zsh. # nice, have zsh\n",
        "\n",
        "chsh -s /usr/bin/zsh\n",
        ">>>chsh: user 'lyt' does not exist in /etc/passwd\n",
        "# ok, failed because lacking admin privileges.\n",
        "\n",
        "getent passwd $(whoami)  # check if account is managed by Centralized identity services\n",
        ">>> XXX:/work/lyt:/bin/csh\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emeM96R8Sp5z"
      },
      "source": [
        "### 2. Change to zsh shell\n",
        "\n",
        "\n",
        "```bash\n",
        "# in server terminal\n",
        "vim .login # for csh shell, it will init by .login file under home directory\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "```bash\n",
        "# add following content into .login file\n",
        "if ( $?ZSH_VERSION == 0 ) then\n",
        "    # echo \"testpoint1:.login\"\n",
        "    if ( -x /usr/bin/zsh ) then\n",
        "        # echo \"testpoint2:.login\"\n",
        "        exec /usr/bin/zsh\n",
        "    else if ( -x /bin/zsh ) then\n",
        "        # echo \"testpoint3:.login\"\n",
        "        exec /bin/zsh\n",
        "    endif\n",
        "endif\n",
        "\n",
        "# enter `:`\n",
        "# enter `wq` for saving and close file\n",
        "```\n",
        "\n",
        "Now re-login through ssh, zsh shell will be processed. If you want to change zsh theme by oh-my-zsh, change it in .zshrc file.\n",
        "\n",
        "\n",
        "```bash\n",
        "# in .zshrc file\n",
        "ZSH_THEME=\"agnoster\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaeCTstvVJPA"
      },
      "source": [
        "Summary:  \n",
        "\n",
        "| File      | load condition | object |\n",
        "| ----------- | ----------- |-----|\n",
        "| .bash_profile | Bash first choice for login config | Bash|\n",
        "| .profile | Universal choice for login config       | sh, dash, ksh, zsh(partial).bash_profile(if no .bash_profile)|\n",
        "|.cshrc | every time shell was exec, like .bshrc for csh | csh, tcsh |\n",
        "|.login | login, similar to .bash_profile | csh, tcsh |\n",
        "|.logout| logout | csh, tcsh |\n",
        "|.bash_logout | bash logout read | bash |\n",
        "|.zlogout| zsh logout read | zsh |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAfe9BSeaVym"
      },
      "source": [
        "## Assign job through slurm\n",
        "srun for interactive job, and sbatch for batch job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9k0jVn2abOK"
      },
      "source": [
        "### 1. Check partition, node list and its state\n",
        "\n",
        "(1) `sinfo`: list all node, partition and its state.\n",
        "\n",
        "| abbreviate | state      | meaning                               |\n",
        "| :--------- | :--------- | ------------------------------------- |\n",
        "| alloc      | allocated  | running task                          |\n",
        "| block      | blocked    |                                       |\n",
        "| comp       | completing |                                       |\n",
        "| down       | down       | node can not be used                  |\n",
        "| drain      | drained    |                                       |\n",
        "| drng       | draining   |                                       |\n",
        "| fail       | fail       |                                       |\n",
        "| failg      | failing    |                                       |\n",
        "| futr       | future     |                                       |\n",
        "| idle       | idle       | node is free and can be used          |\n",
        "| maint      | maint      |                                       |\n",
        "| mix        | mixed      | partial node is free, partial is busy |\n",
        "| npc        | perfctrs   |                                       |\n",
        "| plnd       | planned    |                                       |\n",
        "| pow_dn     | power_down |                                       |\n",
        "| pow_up     | power_up   |                                       |\n",
        "| resv       | reserved   |                                       |\n",
        "| unk        | unknown    |                                       |\n",
        "\n",
        "\n",
        "\n",
        "```bash\n",
        "lyt@cc21dev0  ~  sinfo\n",
        "PARTITION        AVAIL  TIMELIMIT  NODES  STATE NODELIST\n",
        "cluster_short*      up    4:00:00      2   comp cc21cluster[00,13]\n",
        "cluster_short*      up    4:00:00      1    mix cc21cluster05\n",
        "cluster_short*      up    4:00:00     35  alloc cc21cluster[01-04,06-12,14-37]\n",
        "cluster_long        up 4-04:00:00     18  alloc cc21cluster[20-37]\n",
        "cluster_low         up 41-16:00:0      2   comp cc21cluster[00,13]\n",
        "cluster_low         up 41-16:00:0      1    mix cc21cluster05\n",
        "cluster_low         up 41-16:00:0     17  alloc cc21cluster[01-04,06-12,14-19]\n",
        "cluster_intr        up   10:00:00      2   comp cc21cluster[00,13]\n",
        "cluster_intr        up   10:00:00      1    mix cc21cluster05\n",
        "cluster_intr        up   10:00:00     17  alloc cc21cluster[01-04,06-12,14-19]\n",
        "gpu_short           up    4:00:00      5    mix cc21gpu[01-02,04-06]\n",
        "gpu_short           up    4:00:00      1  alloc cc21gpu00\n",
        "gpu_short           up    4:00:00      2   idle cc21gpu[03,07]\n",
        "gpu_long            up 4-04:00:00      3    mix cc21gpu[04-06]\n",
        "gpu_long            up 4-04:00:00      1   idle cc21gpu07\n",
        "gpu_intr            up   10:00:00      5    mix cc21gpu[01-02,04-06]\n",
        "gpu_intr            up   10:00:00      1  alloc cc21gpu00\n",
        "gpu_intr            up   10:00:00      2   idle cc21gpu[03,07]\n",
        "hmem_short          up    4:00:00      1  alloc cc21hmem00\n",
        "hmem_short          up    4:00:00      1   idle cc21hmem01\n",
        "hmem_long           up 4-04:00:00      1  alloc cc21hmem00\n",
        "hmem_long           up 4-04:00:00      1   idle cc21hmem01\n",
        "hmem_intr           up   10:00:00      1  alloc cc21hmem00\n",
        "hmem_intr           up   10:00:00      1   idle cc21hmem01\n",
        "msas_short          up    4:00:00      1    mix cc21msas\n",
        "msas_long           up 4-04:00:00      1    mix cc21msas\n",
        "msas_intr           up   10:00:00      1    mix cc21msas\n",
        "azuregpu1_long      up 4-04:00:00      5  idle~ cc19azuregpu[100-104]\n",
        "azuregpu1_intr      up   10:00:00      5  idle~ cc19azuregpu[100-104]\n",
        "ocigpu8a100_long    up 4-04:00:00      1  idle~ cc21ocigpu8a110\n",
        "ocigpu8a100_long    up 4-04:00:00      1 drain~ cc21ocigpu8a100\n",
        "ocigpu8a100_intr    up   10:00:00      1  idle~ cc21ocigpu8a110\n",
        "ocigpu8a100_intr    up   10:00:00      1 drain~ cc21ocigpu8a100\n",
        "ocigpu1a10_long     up 4-04:00:00      7  idle~ cc21ocigpu1a[001-007]\n",
        "ocigpu1a10_long     up 4-04:00:00      1    mix cc21ocigpu1a000\n",
        "ocigpu1a10_intr     up   10:00:00      7  idle~ cc21ocigpu1a[001-007]\n",
        "ocigpu1a10_intr     up   10:00:00      1    mix cc21ocigpu1a000\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Assign partition or node for your work      \n",
        "\n",
        "(1). Assign partition or node in command line\n",
        "\n",
        "- `srun` case\n",
        "  \n",
        "```bash\n",
        "# interactive pattern: srun -p cluster_intr --pty bash -l\n",
        "# -p -> partition \n",
        "lyt@cc21dev0 ~ srun -p cluster_intr --pty bash -l\n",
        "\n",
        "srun: job 3468405 queued and waiting for resources\n",
        "srun: job 3468405 has been allocated resources\n",
        "testpoin1: .profile  # This line comes because I add a testpoint in .profile file, it is clear that srun read '.profile' config file.\n",
        "lyt@cc21cluster05:~$  # in this case, cc21cluster05 node was allocated to me, the following command will be excuted in this node.\n",
        "```\n",
        "\n",
        "Let's run test.sh file for testing, the file content as following:\n",
        "```\n",
        "#!/bin/bash -l\n",
        "success test.\n",
        "```\n",
        "\n",
        "Under interactive mode, we can send command like this ðŸ‘‡\n",
        "```bash\n",
        "lyt@cc21cluster05: bash test.sh\n",
        "success test.\n",
        "\n",
        "lyt@cc21cluster05: exit  # logout node\n",
        "logout\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `sbatch` case     \n",
        "  \n",
        "you can assign batch job by `sbatch`, the parameter can be assigned in bash script file through '#SBATCH' or in command line.\n",
        "The priority: command > script, so if same parameter is provided in command, it will replace that in script.\n",
        "\n",
        "Now example, we have a file called 'test_cpu_run.sh' under 'GPU_test' folder.\n",
        "The content is like:\n",
        "```\n",
        "#!/bin/bash -l\n",
        "#SBATCH -p azuregpu1_intr  # Notice, here I assigned 'azuregpu1_intr' partition, later I will reassign in command line. \n",
        "#SBATCH --chdir=/work/lyt  # working path\n",
        "#SBATCH --job-name=test_cpu\n",
        "#SBATCH --output=test_cpu_output.txt  # output will recorded in this file and save in your work space.\n",
        "\n",
        "# Load modules if necessary, e.g., Anaconda or Python environment\n",
        "# module load anaconda\n",
        "# source activate your_env\n",
        "\n",
        "echo \"Starting CPU job...list miniconda if installed\"\n",
        "apt list --installed | grep miniconda\n",
        "echo \"Job finished.\"\n",
        "```\n",
        "\n",
        "```bash\n",
        "# batch job mode: sbatch -p cluster_intr GPU_test/test_cpu_run.sh\n",
        "lyt@cc21dev0 ~ sbatch -p cluster_low GPU_test/test_cpu_run.sh  # Notice here I covered the -p parameter in command line.\n",
        "\n",
        "Submitted batch job 3468410\n",
        "```\n",
        "\n",
        "\n",
        "Check 'work/lyt/' folder, 'test_cpu_output.txt' file was saved, output as following:\n",
        "\n",
        "```text\n",
        "testpoin1: .profile\n",
        "Starting CPU job...list miniconda if installed\n",
        "\n",
        "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
        "\n",
        "Job finished.\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "sbatch parameter:\n",
        "```bash\n",
        "#SBATCH --nodelist=cc21ocigpu1a003\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Cancle job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. verify job ID\n",
        "```bash\n",
        "squeue -u $USER\n",
        "\n",
        "```\n",
        "2. cancel single job\n",
        "```bash\n",
        "scancel [job id]\n",
        "```\n",
        "\n",
        "3. cancel all job\n",
        "```bash\n",
        "scancel -u $USER\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GPU node - super parallel calculation nodes/ Cloud HPC Node (OCI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I only test super parallel calculation nodes(SPC), OCI is not checked yet.\n",
        "Here is the test flow for SPC nodes.\n",
        "\n",
        "(1). `sbatch`\n",
        "\n",
        "In cc21dev0 node, 'test_gpu_run.sh' and 'test_gpu.py' is under GPU_test folder. \n",
        "\n",
        "```bash\n",
        "lyt@cc21dev0  ~ sbatch -p gpu_short GPU_test/test_gpu_run.sh\n",
        "Submitted batch job 3468418\n",
        "```\n",
        "\n",
        "Output file 'test_gpu_output.txt':\n",
        "``` text\n",
        "testpoin1: .profile\n",
        "Starting GPU test job...\n",
        "Running test_gpu.py\n",
        "Traceback (most recent call last):\n",
        "  File \"/work/lyt/GPU_test/test_gpu.py\", line 2, in <module>\n",
        "    import torch\n",
        "ModuleNotFoundError: No module named 'torch'  # Not setting environment yet, so cannot run torch package.\n",
        "Job finished.\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ABFFqbBOf1a"
      },
      "source": [
        "## GPU node - Cloud HPC Node (Azure)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-_LF5X1ma0U"
      },
      "source": [
        "### 1. Copy data and script to azure specific folder\n",
        "\n",
        "Ref:\n",
        "https://itcw3.naist.jp/ITC-local/manual/cc21/Microsoft_Azure_CloudGPU_20230802.pdf\n",
        "(page 17-19)\n",
        "\n",
        "Because Azure HPC center is in American, so need to copy data and script into specific Azure folder 'azure-cc1' through `sftp` interactive command.\n",
        "Azure folder is a temperal place for your work, and has a limitation of 500GB for each user.\n",
        "\n",
        "**copy file/folder from dev node to Azure folder:**\n",
        "\n",
        "\n",
        "```bash\n",
        "# upload folder\n",
        "sftp azure-cc1 <<< 'put -r [dev_node/folder] [remote/folder]'\n",
        "# upload file\n",
        "sftp azure-cc1 <<< 'put [dev_node/file] [remote/file]'\n",
        "\n",
        "# For instance, upload test folder\n",
        "# sftp azure-cc1 <<< 'put -r test test'\n",
        "\n",
        "```\n",
        "\n",
        "**get file/folder from Azure folder to dev node:**\n",
        "```bash\n",
        "# get folder\n",
        "sftp azure-cc1 <<< 'get -r [remote/folder] [dev_node/folder]'\n",
        "# get file\n",
        "sftp azure-cc1 <<< 'put [remote/file] [dev_node/file]'\n",
        "\n",
        "# For instance, upload test folder\n",
        "# sftp azure-cc1 <<< 'get test test'\n",
        "\n",
        "```\n",
        "\n",
        "**It is also possible using interactive style:**\n",
        "```bash\n",
        "# open interactive line\n",
        "sftp azure-cc1\n",
        "\n",
        "# list file/folders\n",
        "ls\n",
        "\n",
        "# remove file/folders\n",
        "rm [file]\n",
        "rm -r [folder]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoBjCLElO4nt"
      },
      "source": [
        "### 2. Interactive command\n",
        "\n",
        "open a GPU node in interactive environment\n",
        "\n",
        "```bash\n",
        "srun â€“p azuregpu1_intr --gres=gpu:1 --chdir=/work/(account) --pty bash\n",
        "# For instance\n",
        "# srun â€“p azuregpu1_intr --gres=gpu:1 --chdir=/work/lyt --pty bash\n",
        "```\n",
        "\n",
        "\n",
        "Memo: Azure HPC has really heavy delay, maybe that's why it is idle. ðŸ¤·\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Others\n",
        "- Usage limitation\n",
        "- Conda environment should install in which node?\n",
        "- What's the diffrence between `module load` and conda virtual environment\n",
        "- How to keep ssh connection alive all the time? (client_loop: send disconnect: Broken pipe)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Usage limitation\n",
        "\n",
        "1. Space limitation\n",
        "   \n",
        "| dir            | Total storage | Max storage/person |\n",
        "| -------------- | ------------- | ------------------ |\n",
        "| /work          | 200 TB        | -                  |\n",
        "| azurecc-1/work | 2 TB          | 512 GB             |\n",
        "| /home          |               |                    |\n",
        "| /project       |               |                    |\n",
        "|                |               |                    |\n",
        "\n",
        "2. System-wide restrictions\n",
        "Number of concurrent jobs submitted per user: 4160\n",
        "Number of concurrent job executions per user: 4160\n",
        "Arrays per array job: 4160"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conda environment should install in which node?\n",
        "Conda environment should install in development node cc21dev0 or cc21dev1.\n",
        "Because every calculation node could access cc21dev0 node [mandara account]/work/, however, the calculation node assigned to you is dynamic.\n",
        "So setting your virtual environment like conda under cc21dev0 node, and write following lauch command in your running bash script.\n",
        "\n",
        "```bash\n",
        "source /work/lyt/miniconda3/bin/activate\n",
        "conda activate [myenv]  # myenv is your environment name, don't need typing [].\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What does these complier do?\n",
        "There many modules in system, you could check the list by `module avail`.\n",
        "Load module by `module load [name]`.\n",
        "Check your loaded module by `module list`.\n",
        "```bash\n",
        "2025-04-11 module avail\n",
        "\n",
        "-----------------------------------------  /etc/environment-modules/modules ------------------------------------------\n",
        "compiler/intel/2024.1.0            compiler/nvhpc-openmpi3/23.11  java/17/          MATLAB/R2023a      mpi/openmpi/4.1.5      sys/slurm\n",
        "compiler/nvhpc-byo-compiler/22.2   compiler/nvhpc/22.2            java/17/0/11      MATLAB/R2024a      profiler/nvidia/22.2\n",
        "compiler/nvhpc-byo-compiler/23.11  compiler/nvhpc/23.11           java/21/0/3       mkl/2024.1         profiler/vtune/2024.1\n",
        "compiler/nvhpc-nompi/22.2          cuda/11.6u1                    mathematica/13.0  mpi/intel/2021.12  R/4.1.3\n",
        "compiler/nvhpc-nompi/23.11         cuda/12.2u2                    MATLAB/R2022a     mpi/openmpi/4.1.3  singularity/3.9.6\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is a short summary generated by chatgpt4o about what these modules could do (welcome to supplement or point out mistakes):\n",
        "```markdown\n",
        "â¸»\n",
        "\n",
        "ðŸ§  Compiler Modules\n",
        "\n",
        "compiler/intel/2024.1.0\t\t\n",
        "\tâ€¢\tIntel compiler suite (C/C++/Fortran)\t\t\t\n",
        "\tâ€¢\tOptimized for high-performance numerical computing\t\t\n",
        "\tâ€¢\tWorks well with Intel MKL\t\t\n",
        "\tâ€¢\tGreat for simulation, computational chemistry, climate models\t\t\n",
        "\n",
        "compiler/nvhpc/* (NVIDIA HPC SDK)\n",
        "\tâ€¢\tDesigned for GPU-accelerated computing\t\t\n",
        "\tâ€¢\tSupports CUDA Fortran, OpenACC, OpenMP Offload\t\t\n",
        "\tâ€¢\tVersions:\t\t\n",
        "\tâ€¢\tnvhpc/22.2, nvhpc/23.11: Standard GPU-enabled versions\t\t\n",
        "\tâ€¢\tnvhpc-nompi/*: Versions without MPI support\t\t\n",
        "\tâ€¢\tnvhpc-openmpi3/23.11: Comes with OpenMPI3 pre-integrated\t\t\n",
        "\tâ€¢\tnvhpc-byo-compiler/*: â€œBring Your Own Compilerâ€ for advanced configuration\t\t\n",
        "\n",
        "â¸»\n",
        "\n",
        "ðŸ§® Math Libraries & Numerical Computing\n",
        "\n",
        "mkl/2024.1\t\t\n",
        "\tâ€¢\tIntel Math Kernel Library\t\t\n",
        "\tâ€¢\tOptimized implementations of:\t\t\n",
        "\tâ€¢\tBLAS, LAPACK\t\t\n",
        "\tâ€¢\tFFTs\t\t\n",
        "\tâ€¢\tSparse matrix operations\t\t\n",
        "\tâ€¢\tAccelerates NumPy, SciPy, and machine learning libraries\t\t\n",
        "\n",
        "â¸»\n",
        "\n",
        "ðŸ”¢ CUDA Modules\n",
        "\n",
        "cuda/11.6u1, cuda/12.2u2\n",
        "\tâ€¢\tNVIDIA CUDA Toolkit\t\t\n",
        "\tâ€¢\tIncludes:\t\t\n",
        "\tâ€¢\tnvcc CUDA compiler\t\t\n",
        "\tâ€¢\tcuBLAS, cuDNN, and other GPU libraries\t\t\n",
        "\tâ€¢\tRequired for training or deploying deep learning models on GPUs\t\t\n",
        "\n",
        "â¸»\n",
        "\n",
        "ðŸ”¬ Profiler Tools\n",
        "\n",
        "profiler/nvidia/22.2\n",
        "\tâ€¢\tNVIDIA Nsight tools for GPU performance analysis\n",
        "\n",
        "profiler/vtune/2024.1\t\t\n",
        "\tâ€¢\tIntel VTune Profiler\t\t\n",
        "\tâ€¢\tUsed to analyze:\t\t\t\n",
        "\tâ€¢\tCPU and thread performance\t\t\n",
        "\tâ€¢\tMemory and cache usage\t\t\n",
        "\tâ€¢\tParallel execution bottlenecks\t\t\n",
        "\n",
        "â¸»\n",
        "\n",
        "ðŸ“¡ MPI Modules (Parallel Computing)\n",
        "\n",
        "mpi/openmpi/*\t\t\n",
        "\tâ€¢\tOpen-source MPI (Message Passing Interface)\t\t\n",
        "\tâ€¢\tStandard for distributed memory parallelism\t\t\n",
        "\n",
        "mpi/intel/2021.12\t\t\n",
        "\tâ€¢\tIntel MPI\t\t\n",
        "\tâ€¢\tOffers improved performance with Intel compilers and hardware\t\t\n",
        "\n",
        "â¸»\n",
        "\n",
        "ðŸ§ª Applications / Programming Languages\n",
        "\n",
        "MATLAB\n",
        "\tâ€¢\tMATLAB/R2022a, R2023a, R2024a\t\t\n",
        "\tâ€¢\tUsed for:\t\t\n",
        "\tâ€¢\tData analysis\t\t\n",
        "\tâ€¢\tControl systems\t\t\n",
        "\tâ€¢\tMachine learning and signal processing\t\t\n",
        "\n",
        "R\n",
        "\tâ€¢\tR/4.1.3\t\t\n",
        "\tâ€¢\tWidely used in:\t\t\n",
        "\tâ€¢\tStatistical analysis\t\t\n",
        "\tâ€¢\tData visualization\t\t\n",
        "\tâ€¢\tBioinformatics pipelines (DESeq2, edgeR, Seurat, etc.)\t\t\n",
        "\n",
        "Java\t\t\n",
        "\tâ€¢\tjava/17, java/21\t\t\t\n",
        "\tâ€¢\tFor Java-based applications and tools\t\t\n",
        "\n",
        "â¸»\n",
        "\n",
        "ðŸ“¦ System & Utility Tools\n",
        "\n",
        "sys/slurm\t\t\n",
        "\tâ€¢\tJob scheduler used to submit and manage jobs on the cluster\n",
        "\n",
        "singularity/3.9.6\t\t\t\n",
        "\tâ€¢\tContainer platform (like Docker for HPC)\t\t\n",
        "\tâ€¢\tEnables reproducible workflows\t\t\n",
        "\tâ€¢\tUseful for packaging entire bioinformatics pipelines\t\t\n",
        "\n",
        "â¸»\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What's the diffrence between `module load` and conda virtual environment\n",
        "\n",
        "`module load` is system level complier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How to keep ssh connection alive all the time? (client_loop: send disconnect: Broken pipe)\n",
        "\n",
        "In this situation, try the solution: https://unix.stackexchange.com/questions/602518/ssh-connection-client-loop-send-disconnect-broken-pipe-or-connection-reset\n",
        "\n",
        "Error:\n",
        "\n",
        "```bash\n",
        "Connection to cc21dev0 closed by remote host.\n",
        "Connection to cc21dev0 closed.\n",
        "client_loop: send disconnect: Broken pipe\n",
        "\n",
        "```\n",
        "\n",
        "Solution:\n",
        "\n",
        "```bash\n",
        "vim ~/.ssh/config\n",
        "\n",
        "# add this content in ~/.ssh/config\n",
        "Host *\n",
        "    ServerAliveInterval 20\n",
        "    TCPKeepAlive no\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "hhhhhh\n",
        "hhh\n",
        "hhh      \n",
        "hhh  \n",
        "hhhh hhh    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "datapreprocess",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
